{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>checkpoint_path</th>\n",
       "      <th>checkpoint_number</th>\n",
       "      <th>epoch</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>../../results/meta-llama/Meta-Llama-3.1-8B-Ins...</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>../../results/meta-llama/Meta-Llama-3.1-8B-Ins...</td>\n",
       "      <td>158</td>\n",
       "      <td>2</td>\n",
       "      <td>0.711009</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>../../results/meta-llama/Meta-Llama-3.1-8B-Ins...</td>\n",
       "      <td>475</td>\n",
       "      <td>6</td>\n",
       "      <td>0.703196</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>../../results/meta-llama/Meta-Llama-3.1-8B-Ins...</td>\n",
       "      <td>554</td>\n",
       "      <td>7</td>\n",
       "      <td>0.700565</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>../../results/meta-llama/Meta-Llama-3.1-8B-Ins...</td>\n",
       "      <td>634</td>\n",
       "      <td>8</td>\n",
       "      <td>0.693491</td>\n",
       "      <td>0.849275</td>\n",
       "      <td>0.586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>../../results/meta-llama/Meta-Llama-3.1-8B-Ins...</td>\n",
       "      <td>790</td>\n",
       "      <td>10</td>\n",
       "      <td>0.690531</td>\n",
       "      <td>0.816940</td>\n",
       "      <td>0.598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>../../results/meta-llama/Meta-Llama-3.1-8B-Ins...</td>\n",
       "      <td>713</td>\n",
       "      <td>9</td>\n",
       "      <td>0.682984</td>\n",
       "      <td>0.818436</td>\n",
       "      <td>0.586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>../../results/meta-llama/Meta-Llama-3.1-8B-Ins...</td>\n",
       "      <td>396</td>\n",
       "      <td>5</td>\n",
       "      <td>0.655215</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>../../results/meta-llama/Meta-Llama-3.1-8B-Ins...</td>\n",
       "      <td>237</td>\n",
       "      <td>3</td>\n",
       "      <td>0.630907</td>\n",
       "      <td>0.872792</td>\n",
       "      <td>0.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>../../results/meta-llama/Meta-Llama-3.1-8B-Ins...</td>\n",
       "      <td>317</td>\n",
       "      <td>4</td>\n",
       "      <td>0.621656</td>\n",
       "      <td>0.856140</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                    checkpoint_path  \\\n",
       "0           0  ../../results/meta-llama/Meta-Llama-3.1-8B-Ins...   \n",
       "1           1  ../../results/meta-llama/Meta-Llama-3.1-8B-Ins...   \n",
       "5           5  ../../results/meta-llama/Meta-Llama-3.1-8B-Ins...   \n",
       "6           6  ../../results/meta-llama/Meta-Llama-3.1-8B-Ins...   \n",
       "7           7  ../../results/meta-llama/Meta-Llama-3.1-8B-Ins...   \n",
       "9           9  ../../results/meta-llama/Meta-Llama-3.1-8B-Ins...   \n",
       "8           8  ../../results/meta-llama/Meta-Llama-3.1-8B-Ins...   \n",
       "4           4  ../../results/meta-llama/Meta-Llama-3.1-8B-Ins...   \n",
       "2           2  ../../results/meta-llama/Meta-Llama-3.1-8B-Ins...   \n",
       "3           3  ../../results/meta-llama/Meta-Llama-3.1-8B-Ins...   \n",
       "\n",
       "   checkpoint_number  epoch        f1  precision  recall  \n",
       "0                 79      1  0.728571   0.743750   0.714  \n",
       "1                158      2  0.711009   0.833333   0.620  \n",
       "5                475      6  0.703196   0.819149   0.616  \n",
       "6                554      7  0.700565   0.805195   0.620  \n",
       "7                634      8  0.693491   0.849275   0.586  \n",
       "9                790     10  0.690531   0.816940   0.598  \n",
       "8                713      9  0.682984   0.818436   0.586  \n",
       "4                396      5  0.655215   0.847619   0.534  \n",
       "2                237      3  0.630907   0.872792   0.494  \n",
       "3                317      4  0.621656   0.856140   0.488  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../results/meta-llama/Meta-Llama-3.1-8B-Instruct/error/small_explanation/2024-08-12-14-59-11_explanation/checkpoint-147/first_iteration/2024-08-12-19-33-21_explanation/checkpoint-238/second_iteration/checkpoint-154/third_iteration/validation_results.csv\")\n",
    "#sort by f1\n",
    "df = df.sort_values(by='f1', ascending=False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_with_explanation(product1: str, product2: str, answer: int):\n",
    "    prompt = f\"Do the two entity descriptions refer to the same real-world entity? Entity 1: '{product1}'. Entity 2: '{product2}'.\"\n",
    "\n",
    "    return  {\n",
    "        \"prompt\": prompt,\n",
    "        \"completion\": answer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_df = pd.read_json(\"../../results/meta-llama/Meta-Llama-3.1-8B-Instruct/error/small_explanation/2024-08-12-14-59-11_explanation/checkpoint-147/first_iteration/2024-08-12-19-33-21_explanation/checkpoint-238/second_iteration/checkpoint-154/third_iteration/checkpoint-79/validation_results.json\")\n",
    "validation_with_explanations_df = pd.read_csv(\"../../data/wdc/preprocessed_wdcproducts80cc20rnd000un_valid_small_40_mini.csv\")\n",
    "training_simple_df = pd.read_csv(\"../../data/wdc/preprocessed_wdcproducts80cc20rnd000un_train_small_explanations_40_mini_simple.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all columns from validation_with_explanations_df except pair_id and content\n",
    "validation_with_explanations_df = validation_with_explanations_df[[\"pair_id\", \"content\"]]\n",
    "\n",
    "# merge the two based on pair id \n",
    "merged_df = validated_df.merge(validation_with_explanations_df, on=\"pair_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_most_important_attribute(data_string):\n",
    "    # Split the string into individual attributes\n",
    "    attributes = data_string.split('\\n')\n",
    "\n",
    "    # Initialize variables to track the most important attribute\n",
    "    max_importance = -1\n",
    "    most_important_attribute = \"\"\n",
    "\n",
    "    # Loop through each attribute\n",
    "    for attribute in attributes:\n",
    "        if 'importance=' in attribute:\n",
    "            # Extract the importance value\n",
    "            try:\n",
    "                importance_str = attribute.split('importance=')[1].split('|||')[0]\n",
    "                importance = float(importance_str)\n",
    "            except:\n",
    "                print(f\"Error converting importance value to float. importance_str: {attribute}\")\n",
    "                importance = -1\n",
    "\n",
    "            # Check if this is the most important attribute so far\n",
    "            if importance > max_importance:\n",
    "                max_importance = importance\n",
    "                try:\n",
    "                    most_important_attribute = attribute.split('attribute=')[1].split('|||')[0]\n",
    "                except:\n",
    "                    print(f\"Error extracting most important attribute. attribute: {attribute}\")\n",
    "                    most_important_attribute = \"\"\n",
    "\n",
    "    return most_important_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting importance value to float. importance_str: attribute=game title|||importance=missing|||values=missing###Pokemon S&S2: Rebel Clash|||similarity=0.00  \n",
      "Error converting importance value to float. importance_str: attribute=type|||importance=missing|||values=missing###Trading Card Game|||similarity=0.00  \n"
     ]
    }
   ],
   "source": [
    "# apply the extract_most_important_attribute function to the content column\n",
    "merged_df[\"most_important_attribute\"] = merged_df[\"content\"].apply(extract_most_important_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "most_important_attribute\n",
       "model                         157\n",
       "brand                          23\n",
       "type                           18\n",
       "storage capacity               10\n",
       "product type                    7\n",
       "memory type                     5\n",
       "size                            4\n",
       "socket type                     3\n",
       "speed                           3\n",
       "prints                          2\n",
       "channel count                   2\n",
       "connection type                 2\n",
       "ball size                       2\n",
       "memory capacity                 2\n",
       "series                          2\n",
       "pack size                       1\n",
       "usage                           1\n",
       "macro capability                1\n",
       "number of shots                 1\n",
       "form factor                     1\n",
       "expansion set                   1\n",
       "string gauge                    1\n",
       "case type                       1\n",
       "sheets count                    1\n",
       "wireless standard               1\n",
       "number of exposures/photos      1\n",
       "water resistance                1\n",
       "resolution                      1\n",
       "managed                         1\n",
       "team                            1\n",
       "radiator size                   1\n",
       "band color                      1\n",
       "channel capacity                1\n",
       "aperture                        1\n",
       "core count                      1\n",
       "number of strings               1\n",
       "window panel                    1\n",
       "number of burners               1\n",
       "mic type                        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_classified_df = merged_df[merged_df[\"chatbot_response_clean\"] != merged_df[\"label\"]]\n",
    "miss_classified_df[\"most_important_attribute\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting most important attribute. attribute: attribute/model|||importance=0.95|||values=HyperX Fury 4GB DDR3 1600MHz CL10 Ram###4GB DDR3 1600MHz HyperX Fury Black Series|||similarity=0.90  \n",
      "Error extracting most important attribute. attribute: attribute/socket type|||importance=0.9|||values=AM4###AM4|||similarity=1.00  \n",
      "Error extracting most important attribute. attribute: attribute/socket type|||importance=0.10|||values=AM4###AM4|||similarity=1.00  \n",
      "Error converting importance value to float. importance_str: attribute=frequency|||importance=missing|||values=missing###2666MHz|||similarity=missing  \n",
      "Error converting importance value to float. importance_str: attribute=memory type|||importance=missing|||values=missing###DDR4|||similarity=missing  \n",
      "Error extracting most important attribute. attribute: attribute/storage capacity|||importance=0.9|||values=32GB###32GB|||similarity=1.00  \n",
      "Error extracting most important attribute. attribute: attribute/storage capacity|||importance=0.9|||values=900GB###900GB|||similarity=1.00  \n",
      "Error extracting most important attribute. attribute: attribute/socket type|||importance=0.90|||values=AM4###AM4|||similarity=1.00  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "most_important_attribute\n",
       "model                  12114\n",
       "brand                   2744\n",
       "type                     993\n",
       "storage capacity         731\n",
       "product type             437\n",
       "                       ...  \n",
       "supported processor        1\n",
       "cooling type               1\n",
       "infrared burner            1\n",
       "UHS class                  1\n",
       "standards                  1\n",
       "Name: count, Length: 295, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_large_df = pd.read_csv(\"../../data/wdc/preprocessed_wdcproducts80cc20rnd000un_train_large_40_mini.csv\")\n",
    "# apply the extract_most_important_attribute function to the content column\n",
    "training_large_df[\"most_important_attribute\"] = training_large_df[\"content\"].apply(extract_most_important_attribute)\n",
    "training_large_df[\"most_important_attribute\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_left                          HyperX Fury DDR3 1600MHz 8GB\n",
      "title_right    Memoria DDR3 1600Mhz Kit 8GB HyperX Kingston (...\n",
      "label                                                          0\n",
      "content        No.  \\nattribute=brand|||importance=0.05|||val...\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(miss_classified_df.iloc[0][[\"title_left\", \"title_right\", \"label\", \"content\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title_left': 'HyperX Fury DDR3 1600MHz 8GB', 'title_right': 'Memoria DDR3 1600Mhz Kit 8GB HyperX Kingston (2x4GB)', 'label': 0, 'content': 'No.  \\nattribute=brand|||importance=0.05|||values=HyperX###HyperX|||similarity=1.00  \\nattribute=model|||importance=-0.90|||values=Fury|||Fury Kit|||similarity=0.50  \\nattribute=memory type|||importance=0.10|||values=DDR3###DDR3|||similarity=1.00  \\nattribute=memory speed|||importance=0.10|||values=1600MHz###1600MHz|||similarity=1.00  \\nattribute=memory size|||importance=-0.80|||values=8GB###8GB (2x4GB)|||similarity=0.75  \\nattribute=configuration|||importance=-0.95|||values=Single Module###Dual Channel (2x4GB)|||similarity=0.00  '}\n"
     ]
    }
   ],
   "source": [
    "title_left = miss_classified_df.iloc[0][\"title_left\"]\n",
    "title_right = miss_classified_df.iloc[0][\"title_right\"]\n",
    "label = miss_classified_df.iloc[0][\"label\"]\n",
    "content = miss_classified_df.iloc[0][\"content\"]\n",
    "\n",
    "example = {\n",
    "    \"title_left\": title_left,\n",
    "    \"title_right\": title_right,\n",
    "    \"label\": label,\n",
    "    \"content\": content\n",
    "}\n",
    "\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every entry in the miss_classified_df take 5 examples from the training_large_df that have the same most_important_attribute and the same label\n",
    "# Assuming your dataframes are named miss_classified_df and training_large_df\n",
    "selected_examples = []\n",
    "\n",
    "# Iterate over each row in miss_classified_df\n",
    "for idx, row in miss_classified_df.iterrows():\n",
    "    # Get the most important attribute and label for the current row\n",
    "    attribute = row['most_important_attribute']\n",
    "    label = row['label']\n",
    "    \n",
    "    # Find 5 matching examples in training_large_df\n",
    "    matching_examples = training_large_df[\n",
    "        (training_large_df['most_important_attribute'] == attribute) & \n",
    "        (training_large_df['label'] == label)\n",
    "    ].head(5)\n",
    "    \n",
    "    # Append the matching examples to the list\n",
    "    selected_examples.append(matching_examples)\n",
    "\n",
    "# Combine all selected examples into a single DataFrame\n",
    "selected_examples_df = pd.concat(selected_examples, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicat pai_ids \n",
    "selected_examples_df = selected_examples_df.drop_duplicates(subset=['pair_id'])\n",
    "\n",
    "# convert the selected \n",
    "df_train = selected_examples_df.apply(lambda row: create_prompt_with_explanation(row[\"title_left\"], row[\"title_right\"], row[\"content\"]), axis=1, result_type='expand')\n",
    "\n",
    "df_train.columns = ['prompt', 'completion']\n",
    "\n",
    "# concat df_train with the training_simple_df\n",
    "df_train = pd.concat([df_train, training_simple_df])\n",
    "df_train.to_csv(\"../../results/meta-llama/Meta-Llama-3.1-8B-Instruct/error/small_explanation/2024-08-12-14-59-11_explanation/checkpoint-147/first_iteration/2024-08-12-19-33-21_explanation/checkpoint-238/second_iteration/checkpoint-154/third_iteration/checkpoint-79/enhanced_training.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
