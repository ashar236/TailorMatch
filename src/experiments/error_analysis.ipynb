{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# Load OPENAI_API_KEY from .env file\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_from_string(input_string):\n",
    "    # Find the start and end of the JSON object in the string\n",
    "    start_index = input_string.find('{')\n",
    "    end_index = input_string.rfind('}') + 1\n",
    "    \n",
    "    if start_index != -1 and end_index != -1:\n",
    "        # Extract the JSON string\n",
    "        json_str = input_string[start_index:end_index]\n",
    "        \n",
    "        # Convert the JSON string into a Python object\n",
    "        json_obj = json.loads(json_str)\n",
    "        \n",
    "        return json_obj\n",
    "    else:\n",
    "        raise ValueError(\"No JSON found in the input string.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtration approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(prompt, custom_id):\n",
    "    return {\n",
    "        \"custom_id\": custom_id,\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o-2024-08-06\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            \"max_tokens\": 1000,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "discarded_examples = pd.read_csv(\"../../data/wdc/filtered/small/discarded_examples.csv\")\n",
    "prompt_template = json.load(open(\"../../prompts/error_analysis.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discarded_examples[\"label\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the rows and create the prompts\n",
    "prompts = []\n",
    "for index, row in discarded_examples.iterrows():\n",
    "    # if label = 1, then the system answer is yes, else no\n",
    "    if row[\"label\"] == 1:\n",
    "        system_answer = \"yes\"\n",
    "        correct_answer = \"no\"\n",
    "    else:\n",
    "        system_answer = \"no\"\n",
    "        correct_answer = \"yes\"\n",
    "    \n",
    "    prompt = prompt_template.get(\"prompt\")\n",
    "    prompt = prompt.replace(\"{{entity_1}}\", row[\"title_left\"])\n",
    "    prompt = prompt.replace(\"{{entity_2}}\", row[\"title_right\"])\n",
    "    prompt = prompt.replace(\"{{system_answer}}\", system_answer)\n",
    "    prompt = prompt.replace(\"{{correct_label}}\", correct_answer)\n",
    "    prompts.append(create_prompt(prompt, str(index)))\n",
    "    \n",
    "# Start a batch request\n",
    "batch_file_path = \"filter.jsonl\"\n",
    "with open(batch_file_path, \"w\") as f:\n",
    "    for request in prompts:\n",
    "        f.write(json.dumps(request) + \"\\n\")\n",
    "\n",
    "batch_input_file = client.files.create(\n",
    "    file=open(batch_file_path, \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "\n",
    "batch_input_file_id = batch_input_file.id\n",
    "\n",
    "batch = client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\"description\": \"Error analysis for discarded examples\"}\n",
    ")\n",
    "\n",
    "# delete the batch input file\n",
    "os.remove(batch_file_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(response):\n",
    "    body = response.get(\"body\", {})\n",
    "    usage = body.get(\"usage\", {})\n",
    "    choices = body.get(\"choices\", [{}])\n",
    "    message = choices[0].get(\"message\", {}) if choices else {}\n",
    "\n",
    "    return pd.Series({\n",
    "        \"status_code\": response.get(\"status_code\"),\n",
    "        \"request_id\": response.get(\"request_id\"),\n",
    "        \"completion_id\": body.get(\"id\"),\n",
    "        \"created\": body.get(\"created\"),\n",
    "        \"model\": body.get(\"model\"),\n",
    "        \"content\": message.get(\"content\"),\n",
    "        \"prompt_tokens\": usage.get(\"prompt_tokens\"),\n",
    "        \"completion_tokens\": usage.get(\"completion_tokens\"),\n",
    "        \"total_tokens\": usage.get(\"total_tokens\"),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract values into new columns\n",
    "def extract_error_classes(error_dict, class_number):\n",
    "    error_class =  error_dict.get(str(class_number), None)\n",
    "    if error_class:\n",
    "        return int(error_class)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the batch completions\n",
    "error_analysis = pd.read_json(\"../../data/wdc/filtered/small/discarded_analysis.jsonl\", lines=True)\n",
    "error_analysis_parsed = error_analysis[\"response\"].apply(parse_response)\n",
    "error_analysis = pd.concat([error_analysis, error_analysis_parsed], axis=1)\n",
    "\n",
    "# Extract the json from the content\n",
    "error_analysis[\"error_classes\"] = error_analysis[\"content\"].apply(lambda x: extract_json_from_string(x))\n",
    "# Create new columns for error classes 1 to 9\n",
    "for i in range(1, 10):\n",
    "    error_analysis[f'error_class_{i}'] = error_analysis['error_classes'].apply(lambda x: extract_error_classes(x, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error_class_1': 223, 'error_class_2': 335, 'error_class_3': 239, 'error_class_4': 0, 'error_class_5': 249, 'error_class_6': 34, 'error_class_7': 77, 'error_class_8': 38, 'error_class_9': 0}\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences where the value is greater than 70 for each error class\n",
    "counts = {}\n",
    "for i in range(1, 10):\n",
    "    counts[f'error_class_{i}'] = (error_analysis[f'error_class_{i}'] > 70).sum()\n",
    "\n",
    "# Display the counts\n",
    "print(counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
