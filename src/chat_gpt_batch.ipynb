{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script is used to test an OpenAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import helper\n",
    "from utils import clean_response, parse_response\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Load OPENAI_API_KEY from .env file\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"ft:gpt-4o-mini-2024-07-18:wbsg-uni-mannheim::A1xT61am\",\"ft:gpt-4o-mini-2024-07-18:wbsg-uni-mannheim::A1yQPMEC\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"ft:gpt-4o-mini-2024-07-18:wbsg-uni-mannheim:explanations:9rAaVb9c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_product_descriptions(prompt_template: str, product1: str, product2: str):\n",
    "    # Replace placeholder texts with actual product descriptions\n",
    "    prompt = prompt_template.replace(\"'Entity 1'\", product1).replace(\"'Entity 2'\", product2)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(prompt, custom_id, model, product_1=None, product_2=None):\n",
    "    if product_1 is not None and product_2 is not None:\n",
    "        prompt = insert_product_descriptions(prompt, product_1, product_2)\n",
    "    return {\n",
    "        \"custom_id\": custom_id,\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            \"max_tokens\": 5,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_datasets = [\n",
    "    {\"dataset_name\": \"wdc-fullsize\", \"dataset_path\": \"../data/wdc/wdcproducts80cc20rnd050un_test_gs.pkl\"},\n",
    "    {\"dataset_name\": \"abt-buy-full\", \"dataset_path\": \"../data/abt-buy/abt-buy-gs.pkl\"}, \n",
    "    {\"dataset_name\": \"amazon-google-full\", \"dataset_path\": \"../data/amazon-google/amazon-google-gs.pkl\"},\n",
    "    {\"dataset_name\": \"dblp-acm\", \"dataset_path\": \"../data/dblp-acm/dblp-acm-gs.pkl\"},\n",
    "    {\"dataset_name\": \"dblp-scholar\", \"dataset_path\": \"../data/dblp-scholar/dblp-scholar-gs.pkl\"},\n",
    "    {\"dataset_name\": \"walmart-amazon\", \"dataset_path\": \"../data/walmart-amazon/walmart-amazon-gs.pkl\"}\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34836\n",
      "{'custom_id': 'wdc-fullsize;domain-complex-free (Product);61830419#18905357;0', 'method': 'POST', 'url': '/v1/chat/completions', 'body': {'model': 'ft:gpt-4o-mini-2024-07-18:wbsg-uni-mannheim::A1xT61am', 'messages': [{'role': 'user', 'content': 'Do the two product descriptions refer to the same real-world product? Entity 1: MultiPlus C 12/2000/80-30. Entity 2: DDR4 16GB 3200 Kingston Fury Black.'}], 'max_tokens': 5, 'temperature': 0}}\n",
      "34836\n",
      "{'custom_id': 'wdc-fullsize;domain-complex-free (Product);61830419#18905357;0', 'method': 'POST', 'url': '/v1/chat/completions', 'body': {'model': 'ft:gpt-4o-mini-2024-07-18:wbsg-uni-mannheim::A1yQPMEC', 'messages': [{'role': 'user', 'content': 'Do the two product descriptions refer to the same real-world product? Entity 1: MultiPlus C 12/2000/80-30. Entity 2: DDR4 16GB 3200 Kingston Fury Black.'}], 'max_tokens': 5, 'temperature': 0}}\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    batch_job = []\n",
    "\n",
    "    for dataset in full_datasets:\n",
    "        # Load the dataset\n",
    "        df = pd.read_pickle(dataset[\"dataset_path\"])\n",
    "\n",
    "        # Load all prompts we want to test\n",
    "        with open('../prompts/domain_promts.json', 'r') as file:\n",
    "            prompts = json.load(file)\n",
    "\n",
    "        result_rows = []\n",
    "\n",
    "        for task in prompts:\n",
    "            title = task['title']\n",
    "            prompt_template = task['prompt']\n",
    "\n",
    "            for index, row in df.iterrows():\n",
    "                if \"dblp\" in dataset[\"dataset_name\"]:\n",
    "                    product1 = f\"{row['title_left']}; {row['authors_left']}; {row['venue_left']}; {row['year_left']}\"\n",
    "                    product2=f\"{row['title_right']}; {row['authors_right']}; {row['venue_right']}; {row['year_right']}\"\n",
    "                else:\n",
    "                    product1, product2 = row['title_left'], row['title_right']\n",
    "                    \n",
    "                label = row.get('label') \n",
    "                \n",
    "                custom_id = f\"{dataset['dataset_name']};{title};{row['pair_id']};{label}\"\n",
    "                prompt = create_prompt(prompt_template, custom_id, model, product1, product2)\n",
    "                batch_job.append(prompt)\n",
    "                \n",
    "    print(len(batch_job))\n",
    "    print(batch_job[0])\n",
    "\n",
    "    batch_file_path = \"dblp_filter.jsonl\"\n",
    "    with open(batch_file_path, \"w\") as f:\n",
    "        for request in batch_job:\n",
    "            f.write(json.dumps(request) + \"\\n\")\n",
    "\n",
    "    batch_input_file = client.files.create(\n",
    "        file=open(batch_file_path, \"rb\"),\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "\n",
    "    batch = client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\"description\": \"Test scholar datasets\"}\n",
    "    )\n",
    "\n",
    "    # delete the batch input file\n",
    "    os.remove(batch_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded wdc-fullsize successfully.\n",
      "Loaded abt-buy-full successfully.\n",
      "Loaded amazon-google-full successfully.\n",
      "Loaded dblp-acm successfully.\n",
      "Loaded dblp-scholar successfully.\n",
      "Loaded walmart-amazon successfully.\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to hold the DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Load each dataset into a DataFrame and store in the dictionary\n",
    "for dataset in full_datasets:\n",
    "    dataset_name = dataset[\"dataset_name\"]\n",
    "    dataset_path = dataset[\"dataset_path\"]\n",
    "    try:\n",
    "        df = pd.read_pickle(dataset_path)\n",
    "        dataframes[dataset_name] = df\n",
    "        print(f\"Loaded {dataset_name} successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {dataset_name} from {dataset_path}. Error: {e}\")\n",
    "        \n",
    "# Function to lookup label in the original dataframes using pair_id\n",
    "def lookup_label(row):\n",
    "    dataset_name = row['dataset']\n",
    "    pair_id = row['pair_id']\n",
    "    if dataset_name in dataframes:\n",
    "        original_df = dataframes[dataset_name]\n",
    "        # Assuming pair_id is a unique identifier in the original dataframe\n",
    "        if pair_id in original_df['pair_id'].values:\n",
    "            return original_df.loc[original_df['pair_id'] == pair_id, 'label'].values[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch results saved to batch_output.jsonl\n",
      "batch_JpeFAtrkdejXKiyE3lwJVhEe completed 2024-08-30 18:12:49 file-d2eciGLVxRisn6e7Iw2Br3Vh\n",
      "Batch results saved to batch_output.jsonl\n",
      "batch_08eGvNHcm23hrJTuQE06IolA completed 2024-08-30 18:12:45 file-5MgFICNPuAyx4fqyVFrGTOuT\n",
      "Batch results saved to batch_output.jsonl\n",
      "batch_tZaBH7fYilJlPJgtVnRAMvLh completed 2024-08-30 18:12:35 file-jS8neFCTD78m95q01chFbwJs\n",
      "Batch results saved to batch_output.jsonl\n",
      "batch_8Tr18iUYwIzMjygI4VQuxLgB completed 2024-08-30 18:12:30 file-qv6nYdtjyBsFlW2w3akOPqPN\n",
      "Batch results saved to batch_output.jsonl\n",
      "batch_3YcqKwIINI9lwROscaUMCWEt completed 2024-08-30 17:01:58 file-uJ1fE2HCryhhXSpDKm4tz2Cl\n",
      "Batch results saved to batch_output.jsonl\n",
      "batch_JGuBNsYYvTYRtnvDX6StATqs completed 2024-08-30 17:01:53 file-Sff5nykjAtoiFK9C1NEwpqTu\n",
      "Batch results saved to batch_output.jsonl\n",
      "batch_n4wPLxaMXPQ7loOPmuWWRuZI completed 2024-08-30 17:01:48 file-S1NOw4jmLN1SVAw0Zv1NYenl\n",
      "Batch results saved to batch_output.jsonl\n",
      "batch_6AZrEkx4LTVKgij81t5JG2As completed 2024-08-30 17:01:17 file-4B1TB429rtfi78XgnP6jQhmf\n",
      "Batch results saved to batch_output.jsonl\n",
      "batch_lq9i11cDHYH3ix1d6WuruSNI completed 2024-08-30 17:01:12 file-TEpf0ukzuMEeP6lWWWhw9HO0\n",
      "Batch results saved to batch_output.jsonl\n",
      "batch_XTJzkqQSv1GpTK7Axds5bmWl completed 2024-08-30 17:01:05 file-eWCaLW3aJurlJqE0Ka9wFcmM\n",
      "Batch results saved to batch_output.jsonl\n",
      "batch_kMvIs2CW9Ppo0ADxsfBRy1zN completed 2024-08-30 17:01:00 file-w02AMQGD6W4hMgaTRagK7mPB\n",
      "Batch results saved to batch_output.jsonl\n",
      "batch_vQccOSNLKbtxS28qAsvrQOLN completed 2024-08-30 17:00:54 file-MHklKBCxIhaojCzX1V1RFSZw\n",
      "Batch results saved to batch_output.jsonl\n",
      "batch_BjQ68tvH3bNLEwe0LbtuS31Y completed 2024-08-30 17:00:49 file-oPKDSbPUakgaOfdHC8yprY2c\n",
      "Batch results saved to batch_output.jsonl\n",
      "batch_QIaEst9Dcg8iuDFXz5KoOeC4 completed 2024-08-30 17:00:44 file-wjmwxT1ulkLlpcY9o59PY0O5\n",
      "Batch results saved to batch_output.jsonl\n",
      "batch_YfaCLvFOYcUKu3LRsjZaYwBS completed 2024-08-30 17:00:39 file-5CXhdmAU1q9YQVG3IBwsiCJ2\n",
      "Batch results saved to batch_output.jsonl\n",
      "batch_ld3qI3JybcSBDP8AUPnrzQLf completed 2024-08-30 17:00:34 file-RgCh4BysjjQxhy3PqeKo4xqw\n",
      "Batch results saved to batch_output.jsonl\n",
      "batch_XpW2BqNvZKFVxZ9fXF8Tz98Q completed 2024-08-30 17:00:29 file-sChC4Ignir1TYghRpRGeuSaE\n",
      "Batch results saved to batch_output.jsonl\n",
      "batch_4FHeY0IWzeJRflK1VqEB8w0P completed 2024-08-30 17:00:24 file-beJsyQiGytxmsSePhm3bDq9P\n",
      "Batch results saved to batch_output.jsonl\n",
      "batch_iFBw72cPvlxCTJMX2kS1vn57 completed 2024-08-30 17:00:19 file-7aW66bnO2IeWi1KlkXtVsCzH\n"
     ]
    }
   ],
   "source": [
    "## Download the results\n",
    "batch_list = client.batches.list(limit=19)\n",
    "\n",
    "for batch_job in batch_list.data:\n",
    "    # convert the unix timestamp to a human-readable format\n",
    "    created_at = datetime.utcfromtimestamp(batch_job.created_at).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    output_file_id = batch_job.output_file_id\n",
    "    # Ensure the batch has completed\n",
    "    if output_file_id:\n",
    "        # Step 3: Download the output file content\n",
    "        file_content = client.files.content(output_file_id)\n",
    "        \n",
    "        # Step 4: Write the content to a .jsonl file\n",
    "        with open(f\"../results/gpt-4o-mini/tobedetermined/{output_file_id}.jsonl\", \"w\") as file:\n",
    "            file.write(file_content.text)\n",
    "        \n",
    "        print(\"Batch results saved to batch_output.jsonl\")\n",
    "    else:\n",
    "        print(\"Batch is not completed or output file is not available.\")\n",
    "    print(batch_job.id, batch_job.status, created_at, batch_job.output_file_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
