{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This script transforms dataset into the training schema"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import json\n",
                "import os\n",
                "from dataclasses import dataclass\n",
                "import re\n",
                "\n",
                "import helper as analytics\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "import numpy as np\n",
                "import tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "def list_checkpoint_folders(directory):\n",
                "    checkpoint_folders = []\n",
                "    \n",
                "    for root, dirs, files in os.walk(directory):\n",
                "        for folder in dirs:\n",
                "            if 'checkpoint' in folder:\n",
                "                checkpoint_folders.append(os.path.join(root, folder))\n",
                "                \n",
                "    return checkpoint_folders"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "CHECKPOINT_FOLDER = \"../results/meta-llama/Meta-Llama-3.1-70B-Instruct/small/2024-07-31-09-40-24\"\n",
                "checkpoint_paths = list_checkpoint_folders(CHECKPOINT_FOLDER)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/ceph/aasteine/fine-tuning-paper/env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
                        "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
                    ]
                }
            ],
            "source": [
                "results = []\n",
                "# get all validation files\n",
                "for checkpoint_path in checkpoint_paths:\n",
                "    if not os.path.exists(f\"{checkpoint_path}/validation_results.json\"):\n",
                "        print(f\"Validation results already exist for {checkpoint_path}\")\n",
                "        continue\n",
                "    df = pd.read_json(f\"{checkpoint_path}/validation_results.json\")\n",
                "    df.loc[df['chatbot_response_clean'] == -1, 'chatbot_response_clean'] = 0\n",
                "    f1, precision, recall = analytics.calculate_scores(df)\n",
                "    epoch = analytics.get_epoch_from_checkpoint(checkpoint_paths, int(checkpoint_path.split(\"/\")[-1].replace(\"checkpoint-\", \"\")))\n",
                "    result = {\n",
                "        \"checkpoint_path\": checkpoint_path,\n",
                "        \"checkpoint_number\": checkpoint_path.split(\"/\")[-1].replace(\"checkpoint-\", \"\"),\n",
                "        \"epoch\": epoch,\n",
                "        \"f1\": f1,\n",
                "        \"precision\": precision,\n",
                "        \"recall\": recall\n",
                "    }\n",
                "    results.append(result)\n",
                "df = pd.DataFrame(results)\n",
                "\n",
                "# sort by highest f1\n",
                "df_sorted = df.sort_values(by='f1', ascending=False)\n",
                "df_sorted\n",
                "df.to_csv(f\"{CHECKPOINT_FOLDER}/validation_results.csv\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "def remove_importance_scores(text):\n",
                "    # Define the regex pattern to match both importance and similarity scores\n",
                "    pattern = r'\\|\\|\\|importance=[^|]+|\\|\\|\\|similarity=[^|]+'\n",
                "    \n",
                "    # Substitute the matches with an empty string\n",
                "    cleaned_text = re.sub(pattern, '', text)\n",
                "    \n",
                "    return cleaned_text"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_json('../data/walmart-amazon/walmart-amazon-gs.json.gz', compression='gzip', lines=True)\n",
                "\n",
                "# rename name_left to title_left and name_right to title_right\n",
                "df = df.rename(columns={'name_left': 'title_left', 'name_right': 'title_right'})\n",
                "\n",
                "df.to_pickle('../data/walmart-amazon/walmart-amazon-gs.pkl')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Explanation shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'Yes.  \\nattribute=brand|||values=Seagate###Seagate|||values=IronWolf Pro|||IronWolf Pro|||values=4TB###4TB|||values=3.5|||3.5|||values=missing###7200RPM|||values=missing###128 MB|||values=SATA3###SATA3'"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_with_explanation = pd.read_pickle('../data/wdc/preprocessed_wdcproducts80cc20rnd000un_train_small_explanations_40_mini.pkl.gz', compression='gzip')\n",
                "df_with_explanation[\"explanation\"] = df_with_explanation[\"explanation\"].apply(remove_importance_scores)\n",
                "df_with_explanation.iloc[0][\"explanation\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_prompt_with_explanation(product1: str, product2: str, answer: int):\n",
                "    prompt = f\"Do the two product descriptions refer to the same real-world product? Entity 1: '{product1}'. Entity 2: '{product2}'.\"\n",
                "\n",
                "    return  {\n",
                "        \"prompt\": prompt,\n",
                "        \"completion\": answer\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_train = df_with_explanation.apply(lambda row: create_prompt_with_explanation(row[\"title_left\"], row[\"title_right\"], row[\"explanation\"]), axis=1, result_type='expand')\n",
                "\n",
                "df_train.columns = ['prompt', 'completion']\n",
                "df_train.to_csv(\"../data/wdc/explanations/no_importance_similarity/small_simple.csv\", index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_prompt(product1: str, product2: str, answer: int):\n",
                "    correct = 'Yes' if answer == 1 else 'No'\n",
                "\n",
                "    prompt = f\"Do the two product descriptions refer to the same real-world product? Entity 1: '{product1}'. Entity 2: '{product2}'.\"\n",
                "\n",
                "    return  {\n",
                "        \"prompt\": prompt,\n",
                "        \"completion\": correct\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_prompt_row(row):\n",
                "    answer = row[\"label\"]\n",
                "    product1 = row[\"title_left\"]\n",
                "    product2 = row[\"title_right\"]\n",
                "    correct = 'Yes' if answer == 1 else 'No'\n",
                "\n",
                "    prompt = f\"Do the two entity descriptions refer to the same real-world entity? Entity 1: '{product1}'. Entity 2: '{product2}'.\"\n",
                "\n",
                "    return  {\n",
                "        \"prompt\": prompt,\n",
                "        \"completion\": correct\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "def convert_row_to_chat_format(row):\n",
                "    return {\n",
                "        \"messages\": [\n",
                "            {\"role\": \"user\", \"content\": row['prompt']},\n",
                "            {\"role\": \"assistant\", \"content\": row['completion']}\n",
                "        ]\n",
                "    }\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(\"../data/dblp-scholar/dblp-scholar-valid.csv\")\n",
                "\n",
                "df_train = df.apply(lambda row: create_prompt(f\"{row['title_left']}; {row['authors_left']}; {row['venue_left']}; {row['year_left']}\", f\"{row['title_right']}; {row['authors_right']}; {row['venue_right']}; {row['year_right']}\", row[\"label\"]), axis=1, result_type='expand')\n",
                "\n",
                "df_train.columns = ['prompt', 'completion']\n",
                "df_train.to_csv(\"../data/dblp-scholar/dblp-scholar-valid_temp.csv\", index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## From batch job\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "def parse_response(response):\n",
                "    body = response.get(\"body\", {})\n",
                "    usage = body.get(\"usage\", {})\n",
                "    choices = body.get(\"choices\", [{}])\n",
                "    message = choices[0].get(\"message\", {}) if choices else {}\n",
                "\n",
                "    return pd.Series({\n",
                "        \"status_code\": response.get(\"status_code\"),\n",
                "        \"request_id\": response.get(\"request_id\"),\n",
                "        \"completion_id\": body.get(\"id\"),\n",
                "        \"created\": body.get(\"created\"),\n",
                "        \"model\": body.get(\"model\"),\n",
                "        \"content\": message.get(\"content\"),\n",
                "        \"prompt_tokens\": usage.get(\"prompt_tokens\"),\n",
                "        \"completion_tokens\": usage.get(\"completion_tokens\"),\n",
                "        \"total_tokens\": usage.get(\"total_tokens\"),\n",
                "    })"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "You are trying to merge on object and int64 columns for key 'custom_id'. If you wish to proceed you should use pd.concat",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[11], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m result_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([batch_job_df, parsed_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# merge result_df and training_df based on the custom_id from result_df and the index from training_df\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m result_df \u001b[38;5;241m=\u001b[39m \u001b[43mresult_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcustom_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m df_train \u001b[38;5;241m=\u001b[39m result_df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: create_prompt_with_explanation(\n\u001b[1;32m     18\u001b[0m         row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle_left\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     result_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpand\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m df_train\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompletion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
                        "File \u001b[0;32m/ceph/aasteine/fine-tuning-paper/env/lib/python3.11/site-packages/pandas/core/frame.py:10805\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10786\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m  10787\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m  10788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10801\u001b[0m     validate: MergeValidate \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m  10802\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m  10803\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[0;32m> 10805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10806\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10807\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10808\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10809\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10811\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10812\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10814\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10815\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10816\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10817\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10818\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10819\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/ceph/aasteine/fine-tuning-paper/env/lib/python3.11/site-packages/pandas/core/reshape/merge.py:170\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[1;32m    156\u001b[0m         left_df,\n\u001b[1;32m    157\u001b[0m         right_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
                        "File \u001b[0;32m/ceph/aasteine/fine-tuning-paper/env/lib/python3.11/site-packages/pandas/core/reshape/merge.py:807\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tolerance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys)\n\u001b[1;32m    805\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m--> 807\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
                        "File \u001b[0;32m/ceph/aasteine/fine-tuning-paper/env/lib/python3.11/site-packages/pandas/core/reshape/merge.py:1508\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m   1504\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[1;32m   1505\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1506\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[1;32m   1507\u001b[0m     ):\n\u001b[0;32m-> 1508\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n",
                        "\u001b[0;31mValueError\u001b[0m: You are trying to merge on object and int64 columns for key 'custom_id'. If you wish to proceed you should use pd.concat"
                    ]
                }
            ],
            "source": [
                "batch_job_df = pd.read_json(\"../data/wdc/filtered/large/batch_ECDnc1nkc0yQvrwExqFQERpH_output.jsonl\", lines=True)\n",
                "training_df = pd.read_csv(\"../data/wdc/synthetic/4o/validation/synthetic_examples.csv\")\n",
                "\n",
                "# rename custom_id to pair_id on the training_df\n",
                "training_df = training_df.rename(columns={'custom_id': 'pair_id'})\n",
                "\n",
                "# Apply the function to the response column\n",
                "parsed_df = batch_job_df[\"response\"].apply(parse_response)\n",
                "\n",
                "# Concatenate the original dataframe with the parsed columns\n",
                "result_df = pd.concat([batch_job_df, parsed_df], axis=1)\n",
                "\n",
                "# merge result_df and training_df based on the custom_id from result_df and the index from training_df\n",
                "result_df = result_df.merge(training_df, left_on=\"custom_id\", right_index=True)\n",
                "\n",
                "df_train = result_df.apply(\n",
                "    lambda row: create_prompt_with_explanation(\n",
                "        row[\"title_left\"],\n",
                "        row[\"title_right\"],\n",
                "        f\"{'Yes' if row['label'] == 1 else 'No'}. {row['content']}\"\n",
                "    ),\n",
                "    axis=1,\n",
                "    result_type='expand'\n",
                ")\n",
                "\n",
                "df_train.columns = ['prompt', 'completion']\n",
                "# Include pair_id in df_train\n",
                "df_train['pair_id'] = result_df['pair_id']\n",
                "\n",
                "df_train.to_csv(\"../data/wdc/synthetic/4o/validation/synthetic_with_explanation.csv\", index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "# split custom_id into prompt, pair_id, label, index\n",
                "result_df[['task', 'pair_id', 'label', 'index']] = result_df.custom_id.str.split(\";\", expand=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "19835\n",
                        "19213\n"
                    ]
                }
            ],
            "source": [
                "# tanslate content form Yes/No to 1/0\n",
                "result_df['content'] = result_df['content'].apply(lambda x: 1 if 'Yes' in x else 0)\n",
                "print(len(result_df))\n",
                "\n",
                "# convert label to int\n",
                "result_df['label'] = result_df['label'].astype(int)\n",
                "\n",
                "# filter out all rows where the content is not equal to the label\n",
                "result_df = result_df[result_df['content'] == result_df['label']]\n",
                "print(len(result_df))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_df = pd.read_pickle(\"../data/wdc/train_large/preprocessed_wdcproducts80cc20rnd000un_train_large_embeddings.pkl\")\n",
                "\n",
                "# filter out all pair ids that are not in the result_df\n",
                "train_df = train_df[train_df['pair_id'].isin(result_df['pair_id'])]\n",
                "\n",
                "#df_expanded = training_df.apply(lambda row: create_prompt(row[\"title_left\"], row[\"title_right\"], row[\"label\"]), axis=1, result_type='expand')\n",
                "# Rename the columns to match the desired output\n",
                "#df_expanded.columns = [\"prompt\", \"completion\"]\n",
                "\n",
                "train_df.to_pickle(\"../data/wdc/filtered/large/filtered_large_embeddings.pkl.gz\",  compression='gzip')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>prompt</th>\n",
                            "      <th>completion</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>Do the two entity descriptions refer to the sa...</td>\n",
                            "      <td>No.  \\nattribute=brand|||importance=0.05|||val...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>Do the two entity descriptions refer to the sa...</td>\n",
                            "      <td>Yes.  \\nattribute=brand|||importance=0.05|||va...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>Do the two entity descriptions refer to the sa...</td>\n",
                            "      <td>Yes.  \\nattribute=brand|||importance=0.05|||va...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>Do the two entity descriptions refer to the sa...</td>\n",
                            "      <td>Yes.  \\nattribute=brand|||importance=0.05|||va...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>Do the two entity descriptions refer to the sa...</td>\n",
                            "      <td>No.  \\nattribute=brand|||importance=0.05|||val...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>19830</th>\n",
                            "      <td>Do the two entity descriptions refer to the sa...</td>\n",
                            "      <td>No.  \\nattribute=brand|||importance=0.05|||val...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>19831</th>\n",
                            "      <td>Do the two entity descriptions refer to the sa...</td>\n",
                            "      <td>No.  \\nattribute=brand|||importance=0.05|||val...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>19832</th>\n",
                            "      <td>Do the two entity descriptions refer to the sa...</td>\n",
                            "      <td>No.  \\nattribute=brand|||importance=0.05|||val...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>19833</th>\n",
                            "      <td>Do the two entity descriptions refer to the sa...</td>\n",
                            "      <td>No.  \\nattribute=brand|||importance=0.05|||val...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>19834</th>\n",
                            "      <td>Do the two entity descriptions refer to the sa...</td>\n",
                            "      <td>No.  \\nattribute=brand|||importance=0.05|||val...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>19835 rows × 2 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                  prompt  \\\n",
                            "0      Do the two entity descriptions refer to the sa...   \n",
                            "1      Do the two entity descriptions refer to the sa...   \n",
                            "2      Do the two entity descriptions refer to the sa...   \n",
                            "3      Do the two entity descriptions refer to the sa...   \n",
                            "4      Do the two entity descriptions refer to the sa...   \n",
                            "...                                                  ...   \n",
                            "19830  Do the two entity descriptions refer to the sa...   \n",
                            "19831  Do the two entity descriptions refer to the sa...   \n",
                            "19832  Do the two entity descriptions refer to the sa...   \n",
                            "19833  Do the two entity descriptions refer to the sa...   \n",
                            "19834  Do the two entity descriptions refer to the sa...   \n",
                            "\n",
                            "                                              completion  \n",
                            "0      No.  \\nattribute=brand|||importance=0.05|||val...  \n",
                            "1      Yes.  \\nattribute=brand|||importance=0.05|||va...  \n",
                            "2      Yes.  \\nattribute=brand|||importance=0.05|||va...  \n",
                            "3      Yes.  \\nattribute=brand|||importance=0.05|||va...  \n",
                            "4      No.  \\nattribute=brand|||importance=0.05|||val...  \n",
                            "...                                                  ...  \n",
                            "19830  No.  \\nattribute=brand|||importance=0.05|||val...  \n",
                            "19831  No.  \\nattribute=brand|||importance=0.05|||val...  \n",
                            "19832  No.  \\nattribute=brand|||importance=0.05|||val...  \n",
                            "19833  No.  \\nattribute=brand|||importance=0.05|||val...  \n",
                            "19834  No.  \\nattribute=brand|||importance=0.05|||val...  \n",
                            "\n",
                            "[19835 rows x 2 columns]"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df = pd.read_csv(\"../data/wdc/preprocessed_wdcproducts80cc20rnd000un_train_large_40_mini_explanations.csv\")\n",
                "df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Synthetic data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_json_objects(data):\n",
                "    # Navigate to the nested JSON array\n",
                "    choices = data.get(\"body\", {}).get(\"choices\", [])\n",
                "    \n",
                "    if not choices:\n",
                "        return []\n",
                "\n",
                "    # Extract the JSON objects as a list\n",
                "    message_content = choices[0].get(\"message\", {}).get(\"content\", \"\")\n",
                "    \n",
                "    # Find the JSON array in the message content\n",
                "    start = message_content.find('[')\n",
                "    end = message_content.rfind(']') + 1\n",
                "    \n",
                "    # Extract the JSON array from the string\n",
                "    json_array_str = message_content[start:end]\n",
                "    \n",
                "    # Parse the JSON array\n",
                "    try:\n",
                "        json_array = json.loads(json_array_str)\n",
                "    except json.JSONDecodeError:\n",
                "        json_array = None\n",
                "        \n",
                "    return json_array"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "# only keep custom_id and entity_one, entity_two, and match columns\n",
                "synthetic_df = synthetic_df[[\"custom_id\", \"entity_one\", \"entity_two\", \"match\"]]\n",
                "\n",
                "# convert the match column to a 0 or 1\n",
                "synthetic_df[\"match\"] = synthetic_df[\"match\"].apply(lambda x: 1 if x == True else 0)\n",
                "\n",
                "# drop the last two characters from the custom id\n",
                "synthetic_df[\"custom_id\"] = synthetic_df[\"custom_id\"].apply(lambda x: x[:-2])\n",
                "\n",
                "# rename entity_one to title_left and entity_two to title_right\n",
                "synthetic_df = synthetic_df.rename(columns={\"entity_one\": \"title_left\", \"entity_two\": \"title_right\"})\n",
                "\n",
                "# rename custom_id to pair_id\n",
                "synthetic_df = synthetic_df.rename(columns={\"custom_id\": \"pair_id\"})\n",
                "\n",
                "# rename match to label\n",
                "synthetic_df = synthetic_df.rename(columns={\"match\": \"label\"})\n",
                "\n",
                "synthetic_df.to_csv(\"../data/wdc/synthetic/4o/textual_explanation/examples.csv\", index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "synthetic_df = pd.read_json(\"../data/wdc/synthetic/4o/textual_explanation/batch_M3H2xaBuLy2XyWAIhZSDFMfc_output.jsonl\", lines=True)\n",
                "\n",
                "synthetic_df[\"response\"] = synthetic_df[\"response\"].apply(extract_json_objects)\n",
                "# drop rows where response is None\n",
                "synthetic_df = synthetic_df[synthetic_df[\"response\"].notnull()]\n",
                "\n",
                "# Expand the JSON array into separate rows\n",
                "synthetic_df = synthetic_df.explode(\"response\")\n",
                "\n",
                "# split the response into three columns title_left, title_right, label\n",
                "synthetic_df = pd.concat([synthetic_df.drop(columns=[\"response\"], axis=1), synthetic_df[\"response\"].apply(pd.Series)], axis=1)\n",
                "\n",
                "# reset the index\n",
                "synthetic_df.reset_index(drop=True, inplace=True)\n",
                "\n",
                "#df_train = synthetic_df.apply(lambda row: create_prompt(row[\"entity_one\"], row[\"entity_two\"], row[\"match\"]), axis=1, result_type='expand')\n",
                "\n",
                "#df_train.columns = ['prompt', 'completion']\n",
                "df_train.to_csv(f\"../data/wdc/synthetic/4o/textual_explanation/synthetic_no_explanations_small_{len(df_train)}.csv\", index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "          task                                   chatbot_question  \\\n",
                        "0  explanation  Do the two entity descriptions refer to the sa...   \n",
                        "1  explanation  Do the two entity descriptions refer to the sa...   \n",
                        "2  explanation  Do the two entity descriptions refer to the sa...   \n",
                        "3  explanation  Do the two entity descriptions refer to the sa...   \n",
                        "4  explanation  Do the two entity descriptions refer to the sa...   \n",
                        "\n",
                        "                                chatbot_response_raw  chatbot_response_clean  \\\n",
                        "0  Yes, the two entity descriptions refer to the ...                       1   \n",
                        "1  Yes, the two entity descriptions refer to the ...                       1   \n",
                        "2  Yes, the two entity descriptions refer to the ...                       1   \n",
                        "3  Yes, the two entity descriptions refer to the ...                       1   \n",
                        "4  No, the two entity descriptions do not refer t...                       0   \n",
                        "\n",
                        "    id_left brand_left                                         title_left  \\\n",
                        "0  87617353        NaN           Sony FE 24-240mm F/3.5-6.3 OSS Lens Sony   \n",
                        "1  87617353       None           Sony FE 24-240mm F/3.5-6.3 OSS Lens Sony   \n",
                        "2  54053670       None          Dymo 45017 D1 12mm x 7m Black on Red Tape   \n",
                        "3  22496256       None                Pokemon Booster Pack Sword & Shield   \n",
                        "4  18666720    Corsair  Corsair Crystal Series 570X RGB CC-9011098-WW ...   \n",
                        "\n",
                        "                                    description_left price_left  \\\n",
                        "0                                                NaN    4361.62   \n",
                        "1                                               None    4361.62   \n",
                        "2                                               None      13.43   \n",
                        "3  Welcome to the Galar region with the Pokémon T...     3.99E0   \n",
                        "4  Corsair Crystal Series 570X RGB CC-9011098-WW ...     179.99   \n",
                        "\n",
                        "  priceCurrency_left  ...  brand_right                           title_right  \\\n",
                        "0                PLN  ...          NaN    Sony FE 24-240mm f3.5-6.3 OSS Lens   \n",
                        "1                PLN  ...         None    Sony FE 24-240mm f3.5-6.3 OSS Lens   \n",
                        "2                GBP  ...         None        DYMO 4500 TAPE BLACK/RED 45017   \n",
                        "3                GBP  ...         None  Pokemon TCG: Sword & Shield Boosters   \n",
                        "4                USD  ...         None       AF-S FX 24-85MM F3.5-4.5G ED VR   \n",
                        "\n",
                        "                                   description_right price_right  \\\n",
                        "0  Sony FE 24-240mm f3.5-6.3 OSS Lens Sony FE 24-...         632   \n",
                        "1  Sony FE 24-240mm f3.5-6.3 OSS Lens Sony FE 24-...         632   \n",
                        "2            Dymo 4500 Tape 12mmx7m Black/Red 45017.       11.49   \n",
                        "3                                               None        4.00   \n",
                        "4  The Nikon AF-S NIKKOR 24-85mm f/3.5-4.5G ED VR...      9.99E2   \n",
                        "\n",
                        "  priceCurrency_right specTableContent_right cluster_id_right  \\\n",
                        "0                 GBP                    NaN           740038   \n",
                        "1                 GBP                    NaN           740038   \n",
                        "2                 GBP                    NaN            48435   \n",
                        "3                 GBP                    NaN           991074   \n",
                        "4                 NZD                    NaN            21809   \n",
                        "\n",
                        "             pair_id  label  is_hard_negative  \n",
                        "0  87617353#25113988      1             False  \n",
                        "1  87617353#25113988      1             False  \n",
                        "2  54053670#80725760      1             False  \n",
                        "3  22496256#21044132      1             False  \n",
                        "4  18666720#61306190      0             False  \n",
                        "\n",
                        "[5 rows x 23 columns]\n"
                    ]
                }
            ],
            "source": [
                "# Set the path to your folder containing the JSON files\n",
                "folder_path = '../data/wdc/explanations'\n",
                "\n",
                "# List all JSON files in the directory\n",
                "json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
                "\n",
                "# Read each JSON file and store in a list of DataFrames\n",
                "dataframes = [pd.read_json(os.path.join(folder_path, file)) for file in json_files]\n",
                "\n",
                "# Concatenate all the DataFrames into a single DataFrame\n",
                "combined_df = pd.concat(dataframes, ignore_index=True)\n",
                "\n",
                "# Now you can use combined_df as your single DataFrame containing all the data\n",
                "print(combined_df.head())  # Display the first few rows to check\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "unique_df = combined_df.drop_duplicates(subset='pair_id', keep='first')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply the function and expand the dictionary into separate columns\n",
                "df_expanded = unique_df.apply(lambda row: create_prompt(row[\"title_left\"], row[\"title_right\"], row[\"label\"]), axis=1, result_type='expand')\n",
                "\n",
                "# Rename the columns to match the desired output\n",
                "df_expanded.columns = [\"prompt\", \"completion\"]\n",
                "\n",
                "#df_expanded.to_csv(\"../data/wdc/explanations/domain_complex_free_with_explanation.csv\", index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [],
            "source": [
                "# drop task, chatbot_response_raw, and chatbot_response_clean\n",
                "df_explanations = df_explanations.drop(['task', 'chatbot_response_raw', 'chatbot_response_clean', 'chatbot_question'], axis=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'Yes, the two entity descriptions refer to the same real-world entity, which is the Sony FE 24-240mm f3.5-6.3 OSS lens.\\n\\nThe first entity description uses the format \"Brand Name Model Name\" and includes the manufacturer\\'s name, Sony, followed by the model name, FE 24-240mm F/3.5-6.3 OSS.\\n\\nThe second entity description uses a more simplified format and omits the brand name, instead focusing on the model name, FE 24-240mm f3.5-6.3 OSS.\\n\\nBoth entity descriptions refer to the same lens, which is a telephoto zoom lens produced by Sony for their full-frame mirrorless cameras. The lens has a focal length range of 24-240mm and a maximum aperture of f3.5-6.3, with optical image stabilization (OSS) technology.\\n\\nTherefore, the two entity descriptions are equivalent and refer to the same real-'"
                        ]
                    },
                    "execution_count": 52,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_explanations[\"chatbot_response_raw\"].iloc[0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_explanations.to_csv(\"../data/wdc/explanations/4k_ralph.csv\", index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Chat format"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Testset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "file_path = \"../data/dblp-scholar/dblp-scholar-train.csv\"\n",
                "df_to_convert = pd.read_csv(file_path)\n",
                "\n",
                "df_to_convert = df_to_convert.apply(convert_row_to_chat_format, axis=1)\n",
                "# Convert the DataFrame to a list of dictionaries\n",
                "records = df_to_convert.to_list()\n",
                "\n",
                "# Save each record as a separate JSON object in a .jsonl file\n",
                "with open(f\"{file_path.split('.csv')[0]}_gpt.jsonl\", 'w') as f:\n",
                "    for record in records:\n",
                "        f.write(json.dumps(record) + '\\n')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Validation set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "ename": "KeyError",
                    "evalue": "'label'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
                        "File \u001b[0;32m/ceph/aasteine/fine-tuning-paper/env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
                        "File \u001b[0;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
                        "File \u001b[0;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
                        "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
                        "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
                        "\u001b[0;31mKeyError\u001b[0m: 'label'",
                        "\nThe above exception was the direct cause of the following exception:\n",
                        "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[39], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m validation_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/wdc/preprocessed_wdcproducts80cc20rnd000un_valid_small.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m    \n\u001b[1;32m      2\u001b[0m valdiation_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(validation_file_path)\n\u001b[0;32m----> 4\u001b[0m valdiation_df \u001b[38;5;241m=\u001b[39m \u001b[43mvaldiation_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_prompt_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexpand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m df_to_convert \u001b[38;5;241m=\u001b[39m valdiation_df\u001b[38;5;241m.\u001b[39mapply(convert_row_to_chat_format, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Convert the DataFrame to a list of dictionaries\u001b[39;00m\n",
                        "File \u001b[0;32m/ceph/aasteine/fine-tuning-paper/env/lib/python3.11/site-packages/pandas/core/frame.py:10347\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10333\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10335\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10336\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10337\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10345\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10346\u001b[0m )\n\u001b[0;32m> 10347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[0;32m/ceph/aasteine/fine-tuning-paper/env/lib/python3.11/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/ceph/aasteine/fine-tuning-paper/env/lib/python3.11/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
                        "File \u001b[0;32m/ceph/aasteine/fine-tuning-paper/env/lib/python3.11/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
                        "Cell \u001b[0;32mIn[6], line 2\u001b[0m, in \u001b[0;36mcreate_prompt_row\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_prompt_row\u001b[39m(row):\n\u001b[0;32m----> 2\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m     product1 \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle_left\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m     product2 \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle_right\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
                        "File \u001b[0;32m/ceph/aasteine/fine-tuning-paper/env/lib/python3.11/site-packages/pandas/core/series.py:1111\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
                        "File \u001b[0;32m/ceph/aasteine/fine-tuning-paper/env/lib/python3.11/site-packages/pandas/core/series.py:1227\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1227\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
                        "File \u001b[0;32m/ceph/aasteine/fine-tuning-paper/env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3807\u001b[0m     ):\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
                        "\u001b[0;31mKeyError\u001b[0m: 'label'"
                    ]
                }
            ],
            "source": [
                "validation_file_path = \"../data/wdc/preprocessed_wdcproducts80cc20rnd000un_valid_small.csv\"    \n",
                "valdiation_df = pd.read_csv(validation_file_path)\n",
                "\n",
                "valdiation_df = valdiation_df.apply(create_prompt_row, axis=1, result_type='expand')\n",
                "\n",
                "df_to_convert = valdiation_df.apply(convert_row_to_chat_format, axis=1)\n",
                "# Convert the DataFrame to a list of dictionaries\n",
                "records = df_to_convert.to_list()\n",
                "\n",
                "# Save each record as a separate JSON object in a .jsonl file\n",
                "with open(f\"{validation_file_path.split('.csv')[0]}_gpt.jsonl\", 'w') as f:\n",
                "    for record in records:\n",
                "        f.write(json.dumps(record) + '\\n')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Simple Fine-tuning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(\"../data/wdc/filtered/wdc_small_filtered.csv\")\n",
                "df = df.apply(create_prompt_row, axis=1, result_type='expand')\n",
                "df.to_csv(\"../data/wdc/filtered/wdc_train_small_filtered.csv\", index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "validation_df = pd.read_csv(\"../data/walmart-amazon/walmart-amazon-valid.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_df = pd.read_json(\"../data/walmart-amazon/walmart-amazon-train.json.gz\", compression='gzip', lines=True)\n",
                "# Filter df1 where 'pair_id' is in df2['pair_id']\n",
                "filtered_df = train_df[train_df['pair_id'].isin(validation_df['pair_id'])]\n",
                "filtered_df.to_csv(\"../data/walmart-amazon/walmart-amazon-valid.csv\", index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply the function and expand the dictionary into separate columns\n",
                "df_expanded = df.apply(lambda row: create_prompt(row[\"title_left\"], row[\"title_right\"], row[\"label\"]), axis=1, result_type='expand')\n",
                "\n",
                "# Rename the columns to match the desired output\n",
                "df_expanded.columns = [\"prompt\", \"completion\"]\n",
                "\n",
                "df_expanded.to_csv(\"../data/wdc/preprocessed_wdcproducts80cc20rnd000un_train_medium_domain_complex_force.csv\", index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Applying the conversion to each row and saving the results\n",
                "with open('../data/wdc/preprocessed_wdcproducts80cc20rnd000un_valid_large_domain_complex_free.jsonl', 'w') as f:\n",
                "    for index, row in df_expanded.iterrows():\n",
                "        chat_format = convert_row_to_chat_format(row)\n",
                "        f.write(json.dumps(chat_format) + '\\n')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_expanded.to_json(\"../data/wdc/preprocessed_wdcproducts80cc20rnd000un_valid_large_domain_complex_free.json\", orient='records', lines=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "df[\"prompt\"] = df.apply(lambda row: create_prompt(row[\"title_left\"], row[\"title_right\"], row[\"label\"]), axis=1)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
